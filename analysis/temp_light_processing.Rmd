---
title: "logger"
author: "Shayle Matsuda"
date: "1/5/2022"
output: html_document
editor_options: 
  chunk_output_type: console
---
Light and Temp loggers for Symbiont-Light experiment
Original script by M. Hoban
```{r}
library(fs)
library(reshape2)
library(emmeans)
library(lmerTest)

library(lubridate)# for date parsing
library(tidyverse)
```

```{r}
#load data
csv_files <- dir_ls("data/light_logger_files",glob="*.CSV",recurse = TRUE)

loggers <- map_dfr(csv_files,function(csv) {
  logger_id <- path_ext_remove(path_file(csv))
  if (str_detect(logger_id,"^(.+)_")) {
    logger_id <- str_match(logger_id,"^(.+)_")[1,2]
  }
  return(
    read_csv(csv,
             skip = 9, # skip 9 rows
             col_names = c("scan_number","date","time","raw","calibrated"), # name our columns
             col_types = "nccnn") %>% 
      mutate(across(where(is.character), str_trim)) %>% 
      mutate(
        datetime = parse_date_time(str_c(date," ",time), orders = c("d/m/y H:M:S","d/m/Y H:M:S"),tz="HST"),
        logger = factor(str_c("logger_",logger_id))
      ) %>%
      dplyr::select(logger, datetime, raw, calibrated)  
  )
})

loggers_wide <- loggers %>%
  dplyr::select(-raw) %>% # get rid of the raw column
  pivot_wider(names_from="logger",values_from="calibrated") %>%
  arrange(datetime)


# trim out the time frame of the experiment, Oct 29-Jan 8. and remove data during readout times. 
loggers_wide <- loggers_wide %>%
                        filter(datetime >= as.Date('2017-10-29') & datetime <= as.Date('2018-01-07')) #
  loggers_wide$date<-date(loggers_wide$datetime) #pull out date

#cut out times when data was pulled from logger, #this removes some of it but not all and not sure why but oh well?
  loggers_wide<-loggers_wide%>%
     filter(!(date == '2017-11-01'))%>%
     filter(!(date == '2017-11-18'))%>%
     filter(!(date == '2017-11-29'))%>%
     filter(!(date == '2017-11-04'))%>%
     filter(!(date == '2017-11-06'))%>%
     filter(!(date == '2017-12-07'))%>%
     filter(!(date == '2017-12-08'))

# save the wide version of the file to CSV
#write_csv(loggers_wide,"loggers_wide_20220713.csv")

#REMOVE LOGGER 6377 no cal file
loggers_wide = subset(loggers_wide, select = -c(logger_6377) )
Mcap.light<-loggers_wide #make a copy

##############
#Logger Calibration

# logger 2488 calibration: y=0.06069x R^2=0.999
Mcap.light$logger_2488CAL <- Mcap.light$logger_2488 * 0.06069
# logger 6378 calibration: y=0.1182x R^2=0.999
Mcap.light$logger_6378CAL <- Mcap.light$logger_6378 * 0.1182
# logger 7272 calibration: y=0.06658x R^2=0.999
Mcap.light$logger_7272CAL <- Mcap.light$logger_7272 * 0.06658
# logger 7274 calibration: y=0.06628x R^2=0.999
Mcap.light$logger_7274CAL <- Mcap.light$logger_7274 * 0.06628
# logger 7277 calibration: y=0.06787x R^2=0.999
Mcap.light$logger_7277CAL <- Mcap.light$logger_7277 * 0.06787
# logger 7278 calibration: y=0.05946x R^2=0.999
Mcap.light$logger_7278CAL <- Mcap.light$logger_7278 * 0.05946
# logger 7279 calibration: y=0.07278x R^2=0.999
Mcap.light$logger_7279CAL <- Mcap.light$logger_7279 * 0.07278
# logger 7280 calibration: y=0.06481x R^2=0.999
Mcap.light$logger_7280CAL <- Mcap.light$logger_7280 * 0.06481
# logger 10956 calibration: y=0.05712x R^2=1
Mcap.light$logger_10956CAL <- Mcap.light$logger_10956 * 0.05712
# logger 10957 calibration: y=0.05758x R^2=0.999
Mcap.light$logger_10957CAL <- Mcap.light$logger_10957 * 0.05758
# logger 10959 calibration: y=0.06052x R^2=1
Mcap.light$logger_10959CAL <- Mcap.light$logger_10959 * 0.06052

Mcap.light.2<- subset(Mcap.light, select = c( 1, 18:28)) #keep cols you need

logger.df<-read.csv("data/metadata/UROP_logger_locations.csv") #read in logger tank locations

Mcap.light.2.melt<- #melt the df and then add metadata
  Mcap.light.2%>% 
   pivot_longer(
    cols=!datetime,
    names_to="Light.logger",
    values_to = "Light")

#merge with metadata
Mcap.light.2.melt.meta<-inner_join(Mcap.light.2.melt, logger.df, by="Light.logger")
Mcap.light.2.melt.meta$Light.logger<-as.factor(Mcap.light.2.melt.meta$Light.logger)
Mcap.light.2.melt.meta$Shade<-as.factor(Mcap.light.2.melt.meta$Shade)
Mcap.light.2.melt.meta$Temp.logger<-as.factor(Mcap.light.2.melt.meta$Temp.logger)
Mcap.light.2.melt.meta$Tank<-as.factor(Mcap.light.2.melt.meta$Tank)

#plots
light_plot<-ggplot(data=Mcap.light.2.melt.meta, aes(x=datetime, y=Light, group = Shade, color=Shade)) +
  geom_line(aes(color=Shade), linetype=2, show.legend = T)+
  xlab("") + 
  theme_bw() + 
  theme(axis.line = element_line(color = 'black'), 
        axis.title=element_text(size=14,face="bold"), 
        panel.border = element_blank(),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        text = element_text(size=18),  
        plot.background =element_blank(), 
        legend.key = element_blank()) + 
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_rect(colour = "black", size=1))+
  theme(aspect.ratio=1)+
  ylab(expression(paste("Light"))) +
  ggtitle("UROP light")+
  theme(plot.title = element_text(size=20, face = "italic"));light_plot 

light_plot+facet_wrap(~Shade, scales = "free_y")
light_plot + xlim(as_datetime("2017-11-30"),  as_datetime("2017-12-01"))

light_plot<-ggplot(data=Mcap.light.2.melt.meta, aes(x=datetime, y=Light, color=Light.logger)) +
  geom_line(aes(color=Light.logger), linetype=2, show.legend = T)+
  xlab("") + 
  theme_bw() + 
  theme(axis.line = element_line(color = 'black'), 
        axis.title=element_text(size=14,face="bold"), 
        panel.border = element_blank(), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        text = element_text(size=18),  
        plot.background =element_blank(), 
        legend.key = element_blank()) + 
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_rect(colour = "black", size=1))+
  theme(aspect.ratio=1)+
  ylab(expression(paste("Light"))) +
  ggtitle("UROP light")+
  theme(plot.title = element_text(size=20, face = "italic"));light_plot 

light_plot+facet_wrap(~Shade)
light_plot + xlim(as_datetime("2017-11-30"),  as_datetime("2017-12-01"))

light_plot<-ggplot(data=Mcap.light.2.melt.meta, aes(x=datetime, y=Light, group = Shade, color=Shade)) +
  geom_smooth(aes(color=Shade), linetype=2, show.legend = T)+
  xlab("") + 
  theme_bw() + 
  theme(axis.line = element_line(color = 'black'), 
        axis.title=element_text(size=14,face="bold"), 
        panel.border = element_blank(), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        text = element_text(size=18),  
        plot.background =element_blank(), 
        legend.key = element_blank()) + 
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_rect(colour = "black", size=1))+
  theme(aspect.ratio=1)+
  ylab(expression(paste("Light"))) +
  ggtitle("Light")+
  theme(plot.title = element_text(size=20, face = "italic"));light_plot

Mcap.light.2.melt.meta <- Mcap.light.2.melt.meta %>%
  mutate(time.point = case_when(date(datetime) < "2017-11-29" ~ "T1",
                                date(datetime) >="2017-11-29" ~ "T2"))
```

#Calc DLI, models, and plot DLI
```{r}
# Calculate average daily light integral for each shade treatment

# number of loggers
Mcap.light.2.melt.meta %>%
  distinct(Light.logger, Shade) %>%
  arrange(Shade)
# 11 loggers

# Plot DLI over time
daily_dli <- Mcap.light.2.melt.meta %>%
  group_by(Light.logger, date = date(datetime), Shade) %>%     # group by light logger and day
  summarise(dli = sum(Light, na.rm = T) / n() * 0.0864) 

ggplot(daily_dli, aes(x = date, y = dli)) +
  geom_line() +
  facet_wrap(~Light.logger)

# Calculate overall average DLI for each treatment
light_res <- Mcap.light.2.melt.meta %>%
  group_by(Light.logger, date = date(datetime), Shade) %>%     # group by light logger and day
  summarise(dli = sum(Light, na.rm = T) / n() * 0.0864) %>%    # calc DLI for each logger on each day
  group_by(Shade) %>%                                          # group by shade treatment
  summarise(avg_dli = mean(dli))                               # calculate average
  
light_res %>%
  arrange(Shade)

light_res_bytimepoint <- Mcap.light.2.melt.meta %>%
  group_by(Light.logger, date = date(datetime), Shade) %>%     # group by light logger and day
  summarise(dli = sum(Light, na.rm = T) / n() * 0.0864) %>%    # calc DLI for each logger on each day
  group_by(Shade, timepoint = date < "2017-11-29") %>%         # group by shade treatment and timepoint (11-29cutoff)
  summarise(avg_dli = mean(dli)) %>%                           # calculate average
  mutate(timepoint = case_when(timepoint == TRUE ~ "T1",
                               timepoint == FALSE ~ "T2"))

# Write to file
#write_csv(light_res_bytimepoint, path = "data/processed/dli.csv")

#### calculate average daily maxima
avg_daily_maxima <- Mcap.light.2.melt.meta %>%
  group_by(Light.logger, date = date(datetime), Shade) %>%     # group by light logger and day
  summarise(max = max(Light)) %>%    # calc max for each logger on each day
  group_by(Shade, timepoint = date < "2017-11-29") %>%         # group by shade treatment and timepoint (11-29cutoff)
  summarise(avg_max = mean(max, na.rm = T)) %>%                           # calculate average
  mutate(timepoint = case_when(timepoint == TRUE ~ "T1",
                               timepoint == FALSE ~ "T2"))

# SHow that avg daily maxima and DLI are proportional
avg_daily_maxima %>%
  arrange(timepoint, avg_max) %>%
  full_join(light_res_bytimepoint) %>%
  pivot_longer(cols = c(avg_max, avg_dli)) %>%
  ggplot(aes(x = Shade, y = value, color = timepoint, group = timepoint)) +
  geom_point() + geom_line() +
  facet_wrap(~name, scales = "free_y")

# model showing light treatments were different from each other, 

#calc daily dli for each logger
light_res.dli <- Mcap.light.2.melt.meta %>%
  group_by(Light.logger, date = date(datetime), time.point, Shade, Tank) %>%     # group by light logger and day
  summarise(dli = sum(Light, na.rm = T) / n() * 0.0864) # calc DLI for each logger on each day
                         
#DLI model
mod <- lme4::lmer(dli ~ Shade*time.point + (1|Tank), 
            data = light_res.dli)
anova(mod)
car::Anova(mod)

emm <- emmeans(mod, ~ Shade*time.point)
contrast(emm, method = "pairwise", by = "time.point")
contrast(emm, method = "pairwise", by = "Shade")

#PAR model 
# mod <- lme4::lmer(Light ~ Shade*time.point + (1|Tank), 
#             data = Mcap.light.2.melt.meta)
# anova(mod)
# car::Anova(mod)
# 
# emm <- emmeans(mod, ~ Shade*time.point)
# contrast(emm, method = "pairwise", by = "time.point")
# contrast(emm, method = "pairwise", by = "Shade")




```

#Temperature Loggers
```{r}
#load data
csv_files <- dir_ls("data/temp_logger",glob="*.csv",recurse = TRUE)

loggers <- map_dfr(csv_files,function(csv) {
  logger_id <- path_ext_remove(path_file(csv))
  if (str_detect(logger_id,"^(.+)_")) {
    logger_id <- str_match(logger_id,"^(.+)_")[1,2]
  }
  return(
     read_csv(
      csv,
      skip = 2,
      #col_select=c(2,3),
      col_types = "ncncccc",
      col_names = FALSE
    ) %>% dplyr::select(2,3) %>%
      dplyr::rename("datetime" = 1, "Temp" = 2) %>%
      mutate(
        datetime = parse_date_time(datetime,"m/d/y I:M:S p", tz="HST"),
        logger = factor(str_c("logger_",logger_id))
      ) %>%
      dplyr::select(logger, datetime, Temp)
  )
  
})

#remove duplicate rows (from when data was not wiped)
loggers<-loggers%>%distinct()

# make wide
loggers_wide <- loggers %>%
  pivot_wider(names_from="logger",values_from="Temp") %>%
  arrange(datetime)

# save the wide version of the file to CSV
#write_csv(loggers_wide,"temploggers_wide_20220713.csv")

loggers_wide$date<-date(loggers_wide$datetime)

loggers_wide <- loggers_wide %>%
                        filter(datetime >= as.Date('2017-10-29') & datetime <= as.Date('2018-01-07')) #exp dates

#remove data when loggers pulled (same as light, confirm)
loggers_wide<-loggers_wide%>%
     filter(!(date == '2017-11-01'))%>%
     filter(!(date == '2017-11-18'))%>%
     filter(!(date == '2017-11-29'))%>%
     filter(!(date == '2017-11-04'))%>%
     filter(!(date == '2017-11-06'))%>%
    filter(!(date == '2017-12-04'))%>%
     filter(!(date == '2017-12-07'))%>%
     filter(!(date == '2017-12-08'))

loggers_wide<-dplyr::select(loggers_wide, -date) 

Mcap.temp<-loggers_wide #make a copy

##############

#melt
Mcap.temp.meta.melt <- melt(Mcap.temp, id = c("datetime"))
names(Mcap.temp.meta.melt)[2]<-"logger"
names(Mcap.temp.meta.melt)[3]<-"temp"

write_csv(Mcap.temp.meta.melt, path = "data/processed/temperature.csv")

temp_plot<-ggplot(data=Mcap.temp.meta.melt, aes(x=datetime, y=temp, color=logger)) +
  geom_line(aes(color=logger), linetype=2, show.legend = F)+
  xlab("") + 
  theme_bw() + 
  theme(axis.line = element_line(color = 'black'), 
        axis.title=element_text(size=14,face="bold"), 
        panel.border = element_blank(), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        text = element_text(size=18),  
        plot.background =element_blank(), 
        legend.key = element_blank()) + 
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_rect(colour = "black", size=1))+
  theme(aspect.ratio=1)+
  ylab(expression(paste("temp"))) +
  ggtitle("Temp")+
  theme(plot.title = element_text(size=20, face = "italic"));temp_plot 

#new tank column
Mcap.temp.meta.melt$logger<-as.character(Mcap.temp.meta.melt$logger)
 Mcap.temp.meta.melt<- Mcap.temp.meta.melt %>%
  mutate(Tank = case_when(
    endsWith(logger, "logger_Tank13") ~ "Tank 13",
      endsWith(logger, "logger_Tank14") ~ "Tank 14",
    endsWith(logger, "logger_Tank17") ~ "Tank 17",
    endsWith(logger, "logger_Tank16") ~ "Tank 16",
    ))
 
 
#SI Fig 1
temp_plot<-ggplot(data=Mcap.temp.meta.melt, aes(x=datetime, y=temp, color=Tank)) +
  geom_smooth(aes(color=Tank), linetype=1, show.legend = T)+
  xlab("") + 
 geom_vline(xintercept = as_datetime("2017-11-29"),
             col = "black", lwd = .5, linetype=2)+
theme_bw() + 
  theme(axis.line = element_line(color = 'black'), 
        axis.title=element_text(size=10,face="bold"), 
        panel.border = element_blank(), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        text = element_text(size=10),  
        plot.background =element_rect(fill="white"), 
        legend.key = element_blank()) + 
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_rect(colour = "black", size=1))+
  theme(aspect.ratio=1)+
  ylab(expression(paste( "Temperature (Â°C)"))) +
  ggtitle("Temperature")+
  theme(plot.title = element_text(size=20, face = "italic"))+
  scale_color_discrete(name="")+
  guides(shape = guide_legend(override.aes = list(size = 0.3)))+
  guides(color = guide_legend(override.aes = list(size = 0.3)))+
  theme(legend.key=element_rect(colour=NA, fill=NA))+
    theme(legend.position = c(0.75, 0.75));temp_plot 

  ggsave(temp_plot, filename = "output/figure_S1.png", width = 100, height = 100, units= "mm")




#Mean temp across tanks
temp_plot<-ggplot(data=Mcap.temp.meta.melt, aes(x=datetime, y=temp)) +
  geom_smooth( linetype=1, show.legend = F)+
  theme_bw() + 
  theme(axis.line = element_line(color = 'black'), 
        axis.title=element_text(size=14,face="bold"), 
        panel.border = element_blank(), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        text = element_text(size=18),  
        plot.background =element_blank(), 
        legend.key = element_blank()) + 
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_rect(colour = "black", size=1))+
  theme(aspect.ratio=1)+
  ylab(expression(paste('Temperature ('*~degree*C*')'))) +
  xlab("")+
  theme(plot.title = element_text(size=20, face = "italic"));temp_plot 



#summary stats

#summary T0-T1
Mcap.temp.T1 <- Mcap.temp.meta.melt %>%
                        filter(datetime >= as.Date('2017-10-29') & datetime <= as.Date('2017-11-29')) #
#mean and median 
Mcap.temp.T1 %>%
  summarise(meantemp = mean(temp, na.rm=T), sd=sd(temp, na.rm=T)) 
Mcap.temp.T1 %>%
  summarise(mediantemp = median(temp, na.rm=T), sd=sd(temp, na.rm=T))  
Mcap.temp.T1 %>%
  summarise(rangetemp = range(temp, na.rm=T), sd=sd(temp, na.rm=T))  

#summary T1-T2
 Mcap.temp.meta.melt %>%
                        filter(datetime >= as.Date('2017-11-29') & datetime <= as.Date('2018-01-07')) #
#mean and median of T1-T2
Mcap.temp.T2 %>%
  summarise(meantemp = mean(temp, na.rm=T), sd=sd(temp, na.rm=T)) 
Mcap.temp.T2 %>%
  summarise(mediantemp = median(temp, na.rm=T), sd=sd(temp, na.rm=T)) 
Mcap.temp.T2 %>%
  summarise(rangetemp = range(temp, na.rm=T), sd=sd(temp, na.rm=T)) 

```

#NOAA BUOY DATA Station MOKH1
```{r}
#https://www.tidyverse.org/blog/2021/03/clock-0-1-0/
library(clock)
library(tidyverse)
library(lubridate)

mok<-read.csv("MOK1_data.csv")
as_tibble(mok)

mok2 <- mok %>%
  mutate(
    date = date_build(year,month,day), 
    .keep = "unused", 
    .before = 1
  )

#remove any temp over 40C bc impossible (NAs as 999s in NOAA data)
mok2<- subset(mok2, degC<40)

#average per month
mok3<-mok2 %>%
  mutate(date = date_group(date, "month")) %>%
  group_by(date) %>%
  dplyr::summarise(avg_temp = mean(degC, na.rm = TRUE), .groups = "drop")
#pull out month
mok4<-mutate(mok3, month = get_month(date))
mok4<-mok4%>%select(month, avg_temp)
#ave per month
mok5<-mok4 %>%
  group_by(month) %>%
  dplyr::summarise(avg_temp = mean(avg_temp, na.rm = TRUE), .groups = "drop")

#load data

NOAA2000<-read.csv("data/NOAA buoy/2000_CO-OPS_1612480_met.csv")
colnames(NOAA2000)[3] = "Temp"
NOAA2000$Temp<-as.numeric(NOAA2000$Temp)

NOAA2001<-read.csv("data/NOAA buoy/2001_CO-OPS_1612480_met.csv")
colnames(NOAA2001)[3] = "Temp"
NOAA2001$Temp<-as.numeric(NOAA2001$Temp)

NOAA2002<-read.csv("data/NOAA buoy/2002_CO-OPS_1612480_met.csv")
colnames(NOAA2002)[3] = "Temp"
NOAA2002$Temp<-as.numeric(NOAA2002$Temp)

NOAA2003<-read.csv("data/NOAA buoy/2003_CO-OPS_1612480_met.csv")
colnames(NOAA2003)[3] = "Temp"
NOAA2003$Temp<-as.numeric(NOAA2003$Temp)

NOAA2004<-read.csv("data/NOAA buoy/2004_CO-OPS_1612480_met.csv")
colnames(NOAA2004)[3] = "Temp"
NOAA2004$Temp<-as.numeric(NOAA2004$Temp)

NOAA2005<-read.csv("data/NOAA buoy/2005_CO-OPS_1612480_met.csv")
colnames(NOAA2005)[3] = "Temp"
NOAA2005$Temp<-as.numeric(NOAA2005$Temp)

NOAA2006<-read.csv("data/NOAA buoy/2006_CO-OPS_1612480_met.csv")
colnames(NOAA2006)[3] = "Temp"
NOAA2006$Temp<-as.numeric(NOAA2006$Temp)

NOAA2007<-read.csv("data/NOAA buoy/2007_CO-OPS_1612480_met.csv")
colnames(NOAA2007)[3] = "Temp"
NOAA2007$Temp<-as.numeric(NOAA2007$Temp)

NOAA2008<-read.csv("data/NOAA buoy/2008_CO-OPS_1612480_met.csv")
colnames(NOAA2008)[3] = "Temp"
NOAA2008$Temp<-as.numeric(NOAA2008$Temp)

NOAA2009<-read.csv("data/NOAA buoy/2009_CO-OPS_1612480_met.csv")
colnames(NOAA2009)[3] = "Temp"
NOAA2009$Temp<-as.numeric(NOAA2009$Temp)

NOAA2010<-read.csv("data/NOAA buoy/2010_CO-OPS_1612480_met.csv")
colnames(NOAA2010)[3] = "Temp"
NOAA2010$Temp<-as.numeric(NOAA2010)

NOAA2011<-read.csv("data/NOAA buoy/2011_CO-OPS_1612480_met.csv")
colnames(NOAA2011)[3] = "Temp"
NOAA2011$Temp<-as.numeric(NOAA2011$Temp)

NOAA2012<-read.csv("data/NOAA buoy/2012_CO-OPS_1612480_met.csv")
colnames(NOAA2012)[3] = "Temp"
NOAA2012$Temp<-as.numeric(NOAA2012$Temp)

NOAA2013<-read.csv("data/NOAA buoy/2013_CO-OPS_1612480_met.csv")
colnames(NOAA2013)[3] = "Temp"
NOAA2013$Temp<-as.numeric(NOAA2013$Temp)

NOAA2014<-read.csv("data/NOAA buoy/2014_CO-OPS_1612480_met.csv")
colnames(NOAA2014)[3] = "Temp"
NOAA2014$Temp<-as.numeric(NOAA2014$Temp)

NOAA2015<-read.csv("data/NOAA buoy/2015_CO-OPS_1612480_met.csv")
colnames(NOAA2015)[3] = "Temp"
NOAA2004$Temp<-as.numeric(NOAA2004$Temp)

NOAA2016<-read.csv("data/NOAA buoy/2016_CO-OPS_1612480_met.csv")
colnames(NOAA2016)[3] = "Temp"
NOAA2004$Temp<-as.numeric(NOAA2004$Temp)

NOAA2017<-read.csv("data/NOAA buoy/2017_CO-OPS_1612480_met.csv")
colnames(NOAA2017)[3] = "Temp"
NOAA2017$Temp<-as.numeric(NOAA2017$Temp)

NOAA2018<-read.csv("data/NOAA buoy/2018_CO-OPS_1612480_met.csv")
colnames(NOAA2018)[3] = "Temp"
NOAA2018$Temp<-as.numeric(NOAA2018$Temp)

NOAA2019<-read.csv("data/NOAA buoy/2019_CO-OPS_1612480_met.csv")
colnames(NOAA2019)[3] = "Temp"
NOAA2019$Temp<-as.numeric(NOAA2019$Temp)

NOAA2020<-read.csv("data/NOAA buoy/2020_CO-OPS_1612480_met.csv")
colnames(NOAA2020)[3] = "Temp"
NOAA2020$Temp<-as.numeric(NOAA2020$Temp)

NOAA2021<-read.csv("data/NOAA buoy/2021_CO-OPS_1612480_met.csv")
colnames(NOAA2021)[3] = "Temp"
NOAA2021$Temp<-as.numeric(NOAA2021$Temp)

NOAA2022<-read.csv("data/NOAA buoy/2022_CO-OPS_1612480_met.csv")
colnames(NOAA2022)[3] = "Temp"
NOAA2022$Temp<-as.numeric(NOAA2022$Temp)


NOAA.df<-rbind(NOAA2000,NOAA2001, NOAA2002,NOAA2003,NOAA2004,NOAA2005,NOAA2006,NOAA2007,NOAA2008,NOAA2009, NOAA2010,
               NOAA2011, NOAA2012,NOAA2013,NOAA2014,NOAA2015,NOAA2016,NOAA2017,NOAA2018,NOAA2019,NOAA2020,NOAA2021,NOAA2022)
NOAA.df$Date<-as.Date(NOAA.df$Date)


NOAA.df<-NOAA.df %>%
  dplyr::mutate(year = lubridate::year(Date), 
                month = lubridate::month(Date), 
                day = lubridate::day(Date))

NOAA.df<-NOAA.df[ -c(1:2,4:5,7) ] #drop unneeded 
colnames(NOAA.df)[1] = "Temp"

NOAA.df$month<-as.factor(NOAA.df$month)
NOAA.df$Temp<-as.numeric(NOAA.df$Temp)


#average per month
NOAA.df2<-NOAA.df %>%
  group_by(month) %>%
  dplyr::summarise(avg_temp = mean(Temp, na.rm = TRUE), .groups = "drop")



```

# Light during acclimation only - 6 days prior, only use highest treatment (others held in treatment tanks)
```{r}
#load data
csv_files <- dir_ls("data/light_logger_files",glob="*.CSV",recurse = TRUE)

loggers <- map_dfr(csv_files,function(csv) {
  logger_id <- path_ext_remove(path_file(csv))
  if (str_detect(logger_id,"^(.+)_")) {
    logger_id <- str_match(logger_id,"^(.+)_")[1,2]
  }
  return(
    read_csv(csv,
             skip = 9, # skip 9 rows
             col_names = c("scan_number","date","time","raw","calibrated"), # name our columns
             col_types = "nccnn") %>% 
      mutate(across(where(is.character), str_trim)) %>% 
      mutate(
        datetime = parse_date_time(str_c(date," ",time), orders = c("d/m/y H:M:S","d/m/Y H:M:S"),tz="HST"),
        logger = factor(str_c("logger_",logger_id))
      ) %>%
      dplyr::select(logger, datetime, raw, calibrated)  
  )
})

loggers_wide <- loggers %>%
  dplyr::select(-raw) %>% # get rid of the raw column
  pivot_wider(names_from="logger",values_from="calibrated") %>%
  arrange(datetime)


# trim out the time frame of data for acclimation, Oct 22-28. and remove data during readout times. 
loggers_wide <- loggers_wide %>%
                        filter(datetime >= as.Date('2017-10-23') & datetime <= as.Date('2017-10-29')) #
  loggers_wide$date<-date(loggers_wide$datetime) #pull out date

#cut out times when data was pulled from logger, 
  # loggers_wide<-loggers_wide%>%
  #    filter(!(date == '2017-11-01'))%>%

#REMOVE LOGGER 6377 no cal file
loggers_wide = subset(loggers_wide, select = -c(logger_6377) )
Mcap.light<-loggers_wide #make a copy

##############
#Logger Calibration

# logger 2488 calibration: y=0.06069x R^2=0.999
Mcap.light$logger_2488CAL <- Mcap.light$logger_2488 * 0.06069
# logger 6378 calibration: y=0.1182x R^2=0.999
Mcap.light$logger_6378CAL <- Mcap.light$logger_6378 * 0.1182
# logger 7272 calibration: y=0.06658x R^2=0.999
Mcap.light$logger_7272CAL <- Mcap.light$logger_7272 * 0.06658
# logger 7274 calibration: y=0.06628x R^2=0.999
Mcap.light$logger_7274CAL <- Mcap.light$logger_7274 * 0.06628
# logger 7277 calibration: y=0.06787x R^2=0.999
Mcap.light$logger_7277CAL <- Mcap.light$logger_7277 * 0.06787
# logger 7278 calibration: y=0.05946x R^2=0.999
Mcap.light$logger_7278CAL <- Mcap.light$logger_7278 * 0.05946
# logger 7279 calibration: y=0.07278x R^2=0.999
Mcap.light$logger_7279CAL <- Mcap.light$logger_7279 * 0.07278
# logger 7280 calibration: y=0.06481x R^2=0.999
Mcap.light$logger_7280CAL <- Mcap.light$logger_7280 * 0.06481
# logger 10956 calibration: y=0.05712x R^2=1
Mcap.light$logger_10956CAL <- Mcap.light$logger_10956 * 0.05712
# logger 10957 calibration: y=0.05758x R^2=0.999
Mcap.light$logger_10957CAL <- Mcap.light$logger_10957 * 0.05758
# logger 10959 calibration: y=0.06052x R^2=1
Mcap.light$logger_10959CAL <- Mcap.light$logger_10959 * 0.06052

Mcap.light.2<- subset(Mcap.light, select = c( 1, 18:28)) #keep cols you need

logger.df<-read.csv("data/metadata/UROP_logger_locations.csv") #read in logger tank locations

Mcap.light.2.melt<- #melt the df and then add metadata
  Mcap.light.2%>% 
   pivot_longer(
    cols=!datetime,
    names_to="Light.logger",
    values_to = "Light")

#merge with metadata
Mcap.light.2.melt.meta<-inner_join(Mcap.light.2.melt, logger.df, by="Light.logger")
Mcap.light.2.melt.meta$Light.logger<-as.factor(Mcap.light.2.melt.meta$Light.logger)
Mcap.light.2.melt.meta$Shade<-as.factor(Mcap.light.2.melt.meta$Shade)
Mcap.light.2.melt.meta$Temp.logger<-as.factor(Mcap.light.2.melt.meta$Temp.logger)
Mcap.light.2.melt.meta$Tank<-as.factor(Mcap.light.2.melt.meta$Tank)

light_plot<-ggplot(data=Mcap.light.2.melt.meta, aes(x=datetime, y=Light, group = Shade, color=Shade)) +
  geom_line(aes(color=Shade), linetype=2, show.legend = T)+
  xlab("") + 
  theme_bw() + 
  theme(axis.line = element_line(color = 'black'), 
        axis.title=element_text(size=14,face="bold"), 
        panel.border = element_blank(),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        text = element_text(size=18),  
        plot.background =element_blank(), 
        legend.key = element_blank()) + 
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_rect(colour = "black", size=1))+
  theme(aspect.ratio=1)+
  ylab(expression(paste("Light"))) +
  ggtitle("UROP light")+
  theme(plot.title = element_text(size=20, face = "italic"));light_plot 

light_plot+facet_wrap(~Shade)
light_plot + xlim(as_datetime("2017-10-23"),  as_datetime("2017-10-29"))

light_plot<-ggplot(data=Mcap.light.2.melt.meta, aes(x=datetime, y=Light, color=Light.logger)) +
  geom_line(aes(color=Light.logger), linetype=2, show.legend = T)+
  xlab("") + 
  theme_bw() + 
  theme(axis.line = element_line(color = 'black'), 
        axis.title=element_text(size=14,face="bold"), 
        panel.border = element_blank(), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        text = element_text(size=18),  
        plot.background =element_blank(), 
        legend.key = element_blank()) + 
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_rect(colour = "black", size=1))+
  theme(aspect.ratio=1)+
  ylab(expression(paste("Light"))) +
  ggtitle("UROP light")+
  theme(plot.title = element_text(size=20, face = "italic"));light_plot 

light_plot+facet_wrap(~Shade)
light_plot + xlim(as_datetime("2017-10-23"),  as_datetime("2017-10-29"))

light_plot<-ggplot(data=Mcap.light.2.melt.meta, aes(x=datetime, y=Light, group = Shade, color=Shade)) +
  geom_smooth(aes(color=Shade), linetype=2, show.legend = T)+
  xlab("") + 
  theme_bw() + 
  theme(axis.line = element_line(color = 'black'), 
        axis.title=element_text(size=14,face="bold"), 
        panel.border = element_blank(), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        text = element_text(size=18),  
        plot.background =element_blank(), 
        legend.key = element_blank()) + 
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_rect(colour = "black", size=1))+
  theme(aspect.ratio=1)+
  ylab(expression(paste("Light"))) +
  ggtitle("Light")+
  theme(plot.title = element_text(size=20, face = "italic"));light_plot

#daily max range and average Mcap.light.2.melt.meta

# Calculate average daily light integral for each shade treatment

# number of loggers
Mcap.light.2.melt.meta %>%
  distinct(Light.logger, Shade) %>%
  arrange(Shade)
# 11 loggers

light_res <- Mcap.light.2.melt.meta %>%
  group_by(Light.logger, date = date(datetime), Shade) %>%     # group by light logger and day
  summarise(dli = sum(Light, na.rm = T) / n() * 0.0864) %>%    # calc DLI for each logger on each day
  group_by(Shade) %>%                                          # group by shade treatment
  summarise(avg_dli = mean(dli))                               # calculate average
  
light_res %>%
  arrange(Shade)

#mean dli by group
light_res_bytimepoint <- Mcap.light.2.melt.meta %>%
  group_by(Light.logger, date = date(datetime), Shade) %>%     # group by light logger and day
  summarise(dli = sum(Light, na.rm = T) / n() * 0.0864) %>%    # calc DLI for each logger on each day
  group_by(Shade, timepoint = date < "2017-11-29") %>%         # group by shade treatment and timepoint (11-29cutoff)
  summarise(avg_dli = mean(dli)) %>%                           # calculate average
  mutate(timepoint = case_when(timepoint == TRUE ~ "T1",
                               timepoint == FALSE ~ "T2"))
#max dli by group
light_res_bytimepoint <- Mcap.light.2.melt.meta %>%
  group_by(Light.logger, date = date(datetime), Shade) %>%     # group by light logger and day
  summarise(dli = sum(Light, na.rm = T) / n() * 0.0864) %>%    # calc DLI for each logger on each day
  group_by(Shade, timepoint = date < "2017-11-29") %>%         # group by shade treatment and timepoint (11-29cutoff)
  summarise(max_dli = max(dli)) %>%                           # calculate average
  mutate(timepoint = case_when(timepoint == TRUE ~ "T1",
                               timepoint == FALSE ~ "T2"))

# Write to file
#write_csv(light_res_bytimepoint, path = "data/processed/dli.csv")

#### calculate average daily maxima
avg_daily_maxima <- Mcap.light.2.melt.meta %>%
  group_by(Light.logger, date = date(datetime), Shade) %>%     # group by light logger and day
  summarise(max = max(Light)) %>%    # calc max for each logger on each day
  group_by(Shade) %>%         # group by shade treatment and timepoint (11-29cutoff)
  summarise(avg_max = mean(max, na.rm = T))                       # calculate averagde)

#avg daily light max for only canopy shade is 314


```

```

